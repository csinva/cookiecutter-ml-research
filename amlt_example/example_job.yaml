description: example job

target:
  service: sing
  name: msrresrchvc
  workspace_name: gcrllama2ws

code:  
  local_dir: /home/chansingh/cookiecutter-ml-research/amlt_example # path to your code on local machine

environment:
  image: amlt-sing/acpt-2.2.1-py3.10-cuda12.1
  setup:
    # working directory is local_dir under code above
    - pip install -r requirements.txt --user # install requirements from file
    # - pip install . # install a package from the local directory


storage:
  data:
    storage_account_name: internblobdl
    container_name: t-chansingh
    mount_dir: /blob_data # path to mount the blob on the remote machine

jobs:
- name: job 1
  process_count_per_node: 1
  
  # sku controls the compute you will use
  # here are some common ones you may use

  # cpu jobs
  # 10C3  # 4 cores, 30 GBs mem
  # 8C7   # 8 cores, 56 GBs mem
  # 8C15  # 15 cores, 120 GBs mem
  # 8C30  # 30 cores, 240 GBs mem
  # 8C60  # 60 cores, 480 GBs mem

  # gpu jobs
  # G1-V100 # 1 V100 GPU
  # G2-V100 # 2 V100 GPUs
  # G1-A100 # 1 A100 GPU
  sku: G1-V100
  command:
  # working directory is local_dir under code above, saves an example txt file into blob
  - echo "Running!" # this is where you would run your python script
  - echo "Succesfully tested on cluster" > /blob_data/test_cluster.txt # saves a file into the blob
  - python example_job_script.py 
  